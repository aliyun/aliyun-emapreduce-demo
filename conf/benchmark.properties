##common
name=KafkaHdfs

## cluster
cluster.cores.total=160
cluster.worker.node.number=5
cluster.memory.per.node.mb=90000

##kafka producer
partition.number=50
topic=st-36
consumer.group=streaming
zookeeper.address=localhost
zookeeper.root=/kafka-1.0.0
broker.list=localhost:9092

##kafka consumer
result.topic=benchmark-result
result.broker.list=localhost:9092

##storm
worker.slot.number=10
# spout.parallelism equals kafka partition.number
#spout.parallelism=25
window.length=10
slide.interval=10
backpressure.enable=false
hdfs.parallelism.factor=1
# trident
# 0 if disable ack
ack.open=true

##spark streaming
#deploy.mode=yarn-client to make use of cluster header node
duration.ms=1000
spark.executor.instances=10
# recerver number=kafka-partition/factor
kafka.partition.receiver.factor=1
spark.yarn.am.memory.mb=20000
spark.yarn.am.cores=15
#default 200ms, recommend >= 50ms
spark.streaming.blockInterval=200ms
# vcore = physical-core *factor
cpu.core.factor=1.5

##hdfs
url=hdfs://emr-header-1:9000
filename.prefix=/foo/
sync.record.number=1000

## metric
benchmark.app.name=KafkaHdfs
metric.numPartitions=100
from.spark.streaming=true
metric.duration.second=60
metric.group.id=kafka-metrics
